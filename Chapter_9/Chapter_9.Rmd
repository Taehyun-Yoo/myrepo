---
title: "Chapter_9"
author: "Taehyun Yoo"
date: '2022-05-22'
output: 
  html_document: 
    keep_md: yes
---

```{r packages, include = FALSE}
#Load packages
library("Rcpp")
library("rstanarm")
library('tidyverse')
library('here')
library("brms")
```

# 9.1 Propagating uncertainty in inference using posterior simulations
```{r 9.1}
hibbs <- here("..", "ElectionsEconomy", "data", "hibbs.dat")
hibbs <- read.table(hibbs, header = TRUE)
hibbs

M1 <- brm(
  vote ~ growth, 
  data = hibbs
)

sims <- as.matrix(M1)
Median <- apply(sims, 2, median)
MAD_SD <- apply(sims, 2, mad)
print(cbind(Median, MAD_SD))
  
#a <- sims[,1]
#b <- sims[,2]
#z <- a/b
#print(c(median(z), mad(z)))
```

# 9.2 Prediction and uncertainty: predict, posterior_linpred, and posterior_predict
```{r 9.2}
new <- data.frame(growth=2.0)

#Point prediction uisng predict
y_point_pred <- predict(M1, newdata=new)
#a_hat <- fixef(M1)[1,1]
#b_hat <- fixef(M1)[2,1]
#y_point_pred <- a_hat + b_hat*new

#Linear predictor with uncertainty using posterior linpred or posterior epred
y_linpred <- posterior_linpred(M1, newdata=new)
a <- sims[,1]
b <- sims[,2]
#y_linpred <- a + b*new

#Predictive distribution for a new distribution using posterior predict
y_pred <- posterior_predict(M1, newdata=new)
n_sims <- nrow(sims)
sigma <- sims[,3]
#y_pred <- as.numeric(a + b*new) + rnorm(n_sims, 0, sigma)

hist(y_pred)
y_pred_median <- median(y_pred)
y_pred_mad <- mad(y_pred)
win_prob <- mean(y_pred > 50)
cat("Predicted Clinton percentage of 2-party vote: ", round(y_pred_median,1),
", with s.e. ", round(y_pred_mad, 1), "\nPr (Clinton win) = ", round(win_prob, 2),
sep="")

new_grid <- data.frame(growth=seq(-2.0, 4.0, 0.5))
y_point_pred_grid <- predict(M1, newdata=new_grid)
y_linpred_grid <- posterior_linpred(M1, newdata=new_grid)
y_pred_grid <- posterior_predict(M1, newdata=new_grid)

x_new <- rnorm(n_sims, 2.0, 0.3)
y_pred <- rnorm(n_sims, a + b*x_new, sigma)

earnings <- here("..", "Earnings", "data", "earnings.csv")
earnings <- read.csv(earnings)
earnings

fit1 <- brm(
  weight ~ height, 
  data = earnings
)
print(fit1)

earnings$c_height <- earnings$height - 66
fit2 <- brm(
  weight ~ c_height, 
  data = earnings
)
print(fit2)

new <- data.frame(c_height=4.0)
y_point_pred_2 <- predict(fit_2, newdata=new)
y_linpred_2 <- posterior_linpred(fit_2, newdata=new)
y_postpred_2 <- posterior_predict(fit_2, newdata=new)
```

# 9.3 Prior information and Bayesian synthesis
```{r 9.3}
theta_hat_prior <- 0.524
se_prior <- 0.041
n <- 400
y <- 190
theta_hat_data <- y/n
se_data <- sqrt((y/n)*(1-y/n)/n)
theta_hat_bayes <- (theta_hat_prior/se_prior^2 + theta_hat_data/se_data^2) /
(1/se_prior^2 + 1/se_data^2)
se_bayes <- sqrt(1/(1/se_prior^2 + 1/se_data^2))
```

# 9.5 Uniform, weakly informative, and informative priors in regression
```{r 9.5}
#Uniform prior distribution
M3 <- stan_glm(vote ~ growth, data=hibbs,
prior_intercept=NULL, prior=NULL, prior_aux=NULL)
sims <- as.data.frame(M3)
a <- sims[,1]
b <- sims[,2]
plot(a, b)

#Default prior distribution
M1 <- stan_glm(vote ~ growth, data=hibbs)
#sd_x <- sd(hibbs$growth)
#sd_y <- sd(hibbs$vote)
#mean_y <- mean(hibbs$vote)
#M1a <- stan_glm(vote ~ growth, data=hibbs, prior=normal(0, 2.5*sd_y/sd_x),
#prior_intercept=normal(mean_y, 2.5*sd_y), prior_aux=exponential(1/sd_y))

#Weakly informative prior distribution based on subject-matter knowledge
M4 <- stan_glm(vote ~ growth, data=hibbs,
prior=normal(5, 5), prior_intercept=normal(50, 10))

#Example where an informative prior makes a difference: Beauty and sex ratio
x <- seq(-2,2,1)
y <- c(50, 44, 50, 47, 56)
sexratio <- data.frame(x, y)

lm_default <- lm(y ~ x, data = sexratio)
print(lm_default)

fit_default <- stan_glm(y ~ x, data=sexratio)
print(fit_default)

fit_post <- stan_glm(y ~ x, data=sexratio,
prior=normal(0, 0.2), prior_intercept=normal(48.8, 0.5))
print(fit_post)
```
